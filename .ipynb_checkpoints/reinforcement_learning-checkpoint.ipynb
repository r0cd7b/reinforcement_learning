{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7460f1b0-7d9d-48b2-b7b4-19ff3bd5b62d",
   "metadata": {
    "id": "7460f1b0-7d9d-48b2-b7b4-19ff3bd5b62d"
   },
   "source": [
    "# 강화 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b50feb-a8db-4c0c-9f9a-afa522f19cc6",
   "metadata": {
    "id": "89b50feb-a8db-4c0c-9f9a-afa522f19cc6"
   },
   "source": [
    "먼저 몇 개의 모듈을 임포트한다. 맷플롯립 그림을 저장하는 함수를 준비한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7630c886-2e78-486e-9ae2-98e94616dc65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7630c886-2e78-486e-9ae2-98e94616dc65",
    "outputId": "4669aa79-394b-4164-b957-05a3fa6946f9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 07:27:13.976103: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 07:27:15.192353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-01 07:27:15.204669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-01 07:27:15.204918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if not tf.config.list_physical_devices(\"GPU\"):\n",
    "    print(\"감지된 GPU가 없습니다. GPU가 없으면 LSTM과 CNN이 매우 느릴 수 있습니다.\")\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc(\"axes\", labelsize=14)\n",
    "mpl.rc(\"xtick\", labelsize=12)\n",
    "mpl.rc(\"ytick\", labelsize=12)\n",
    "\n",
    "# 부드러운 애니메이션을 위해\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "mpl.rc(\"animation\", html=\"jshtml\")\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장 \" + fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, dpi=resolution, format=fig_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214800f",
   "metadata": {},
   "source": [
    "## OpenAI 짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd47ccf",
   "metadata": {},
   "source": [
    "이 노트북은 강화학습 알고리즘을 개발하고 평가하는 훌륭한 도구인 [OpenAI 짐(gym)](https://gym.openai.com/)을 사용한다. 학습 에이전트가 상호작용하기 위한 환경을 많이 제공한다. 먼저 `gym`을 임포트한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d105095-8dc8-4c5f-93ed-ff63c2d24b76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485bddc",
   "metadata": {},
   "source": [
    "가능한 환경 목록을 확인한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5907e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([EnvSpec(id='CartPole-v0', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=0), EnvSpec(id='CartPole-v1', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=1), EnvSpec(id='MountainCar-v0', entry_point='gym.envs.classic_control.mountain_car:MountainCarEnv', reward_threshold=-110.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='MountainCar', version=0), EnvSpec(id='MountainCarContinuous-v0', entry_point='gym.envs.classic_control.continuous_mountain_car:Continuous_MountainCarEnv', reward_threshold=90.0, nondeterministic=False, max_episode_steps=999, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='MountainCarContinuous', version=0), EnvSpec(id='Pendulum-v1', entry_point='gym.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pendulum', version=1), EnvSpec(id='Acrobot-v1', entry_point='gym.envs.classic_control.acrobot:AcrobotEnv', reward_threshold=-100.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Acrobot', version=1), EnvSpec(id='LunarLander-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='LunarLander', version=2), EnvSpec(id='LunarLanderContinuous-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'continuous': True}, namespace=None, name='LunarLanderContinuous', version=2), EnvSpec(id='BipedalWalker-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=1600, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='BipedalWalker', version=3), EnvSpec(id='BipedalWalkerHardcore-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=2000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'hardcore': True}, namespace=None, name='BipedalWalkerHardcore', version=3), EnvSpec(id='CarRacing-v2', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CarRacing', version=2), EnvSpec(id='Blackjack-v1', entry_point='gym.envs.toy_text.blackjack:BlackjackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'sab': True, 'natural': False}, namespace=None, name='Blackjack', version=1), EnvSpec(id='FrozenLake-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.7, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'map_name': '4x4'}, namespace=None, name='FrozenLake', version=1), EnvSpec(id='FrozenLake8x8-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.85, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'map_name': '8x8'}, namespace=None, name='FrozenLake8x8', version=1), EnvSpec(id='CliffWalking-v0', entry_point='gym.envs.toy_text.cliffwalking:CliffWalkingEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CliffWalking', version=0), EnvSpec(id='Taxi-v3', entry_point='gym.envs.toy_text.taxi:TaxiEnv', reward_threshold=8, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Taxi', version=3), EnvSpec(id='Reacher-v2', entry_point='gym.envs.mujoco:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Reacher', version=2), EnvSpec(id='Reacher-v4', entry_point='gym.envs.mujoco.reacher_v4:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Reacher', version=4), EnvSpec(id='Pusher-v2', entry_point='gym.envs.mujoco:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pusher', version=2), EnvSpec(id='Pusher-v4', entry_point='gym.envs.mujoco.pusher_v4:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pusher', version=4), EnvSpec(id='InvertedPendulum-v2', entry_point='gym.envs.mujoco:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedPendulum', version=2), EnvSpec(id='InvertedPendulum-v4', entry_point='gym.envs.mujoco.inverted_pendulum_v4:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedPendulum', version=4), EnvSpec(id='InvertedDoublePendulum-v2', entry_point='gym.envs.mujoco:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=2), EnvSpec(id='InvertedDoublePendulum-v4', entry_point='gym.envs.mujoco.inverted_double_pendulum_v4:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=4), EnvSpec(id='HalfCheetah-v2', entry_point='gym.envs.mujoco:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=2), EnvSpec(id='HalfCheetah-v3', entry_point='gym.envs.mujoco.half_cheetah_v3:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=3), EnvSpec(id='HalfCheetah-v4', entry_point='gym.envs.mujoco.half_cheetah_v4:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=4), EnvSpec(id='Hopper-v2', entry_point='gym.envs.mujoco:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=2), EnvSpec(id='Hopper-v3', entry_point='gym.envs.mujoco.hopper_v3:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=3), EnvSpec(id='Hopper-v4', entry_point='gym.envs.mujoco.hopper_v4:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=4), EnvSpec(id='Swimmer-v2', entry_point='gym.envs.mujoco:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=2), EnvSpec(id='Swimmer-v3', entry_point='gym.envs.mujoco.swimmer_v3:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=3), EnvSpec(id='Swimmer-v4', entry_point='gym.envs.mujoco.swimmer_v4:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=4), EnvSpec(id='Walker2d-v2', entry_point='gym.envs.mujoco:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=2), EnvSpec(id='Walker2d-v3', entry_point='gym.envs.mujoco.walker2d_v3:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=3), EnvSpec(id='Walker2d-v4', entry_point='gym.envs.mujoco.walker2d_v4:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=4), EnvSpec(id='Ant-v2', entry_point='gym.envs.mujoco:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=2), EnvSpec(id='Ant-v3', entry_point='gym.envs.mujoco.ant_v3:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=3), EnvSpec(id='Ant-v4', entry_point='gym.envs.mujoco.ant_v4:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=4), EnvSpec(id='Humanoid-v2', entry_point='gym.envs.mujoco:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=2), EnvSpec(id='Humanoid-v3', entry_point='gym.envs.mujoco.humanoid_v3:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=3), EnvSpec(id='Humanoid-v4', entry_point='gym.envs.mujoco.humanoid_v4:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=4), EnvSpec(id='HumanoidStandup-v2', entry_point='gym.envs.mujoco:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HumanoidStandup', version=2), EnvSpec(id='HumanoidStandup-v4', entry_point='gym.envs.mujoco.humanoidstandup_v4:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HumanoidStandup', version=4)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.envs.registry.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5a7819",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Cart-Pole은 매우 간단한 환경으로 왼쪽과 오른쪽으로 움직이는 카트와 그 위에 수직으로 놓여 있는 막대로 구성된다. 에이전트는 카트를 왼쪽이나 오른쪽으로 움직여 막대가 바로 서 있도록 만들어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b32b650",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5afce",
   "metadata": {},
   "source": [
    "`reset()` 메서드를 호출해 환경을 초기화한다. 이 메서드는 관측을 반환한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22bd7f87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a0c95",
   "metadata": {},
   "source": [
    "관측은 환경에 따라 다르다. 이 경우 4개의 실수로 구성된 1D 넘파이 배열이다. 카트의 수평 위치, 속도, 막대의 각도(0=수직), 각속도를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a349014",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00233274, -0.00235918,  0.04855261,  0.01694405], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a4627",
   "metadata": {},
   "source": [
    "환경은 `render()` 메서드를 호출하여 시각화할 수 있다. 그리고 렌더링 모드(환경에 따른 렌더링 옵션)를 선택할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0df68",
   "metadata": {},
   "source": [
    "**경고**: (Cart-Pole을 포함해) 일부 환경은 화면 접근 권한이 필요하다. `render_mode=\"rgb_array\"`로 지정하더라도 별도의 윈도우를 연다. 일반적으로 이 윈도우를 무시할 수 있다. 하지만 주피터를 백엔드(headless) 서버로 실행한다면 예외가 발생한다. 이를 피하는 한 가지 방법은 [Xvfb](http://en.wikipedia.org/wiki/Xvfb) 같은 가짜 X 서버를 설치하는 것이다. 데비안이나 우분투에서는 다음과 같이 설치한다:\n",
    "\n",
    "```bash\n",
    "$ apt update\n",
    "$ apt install -y xvfb\n",
    "```\n",
    "\n",
    "그다음 `xvfb-run` 명령으로 주피터를 실행한다:\n",
    "\n",
    "```bash\n",
    "$ xvfb-run -s \"-screen 0 1400x900x24\" jupyter notebook\n",
    "```\n",
    "\n",
    "또는 Xvfb를 감싼 [pyvirtualdisplay](https://github.com/ponty/pyvirtualdisplay) 파이썬 라이브러리를 설치할 수 있다:\n",
    "\n",
    "```bash\n",
    "%pip install -U pyvirtualdisplay\n",
    "```\n",
    "\n",
    "그다음 다음 코드를 실행한다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b5ab45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyvirtualdisplay\n",
    "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970ba4b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f0b77",
   "metadata": {},
   "source": [
    "이 예에서는 `render_mode=\"rgb_array\"`로 지정해 환경 이미지를 넘파이 배열로 받는다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e87cb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 600, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = env.render()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e2fe96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_environment(env, figsize=(5, 4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59160b7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_environment(env)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b8ca0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
